{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.34.0 in /home/surenoobster/.local/lib/python3.10/site-packages (4.34.0)\n",
      "Requirement already satisfied: datasets==2.13.0 in /home/surenoobster/.local/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: peft==0.4.0 in /home/surenoobster/.local/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: accelerate==0.23.0 in /home/surenoobster/.local/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: bitsandbytes==0.41.1 in /home/surenoobster/.local/lib/python3.10/site-packages (0.41.1)\n",
      "Requirement already satisfied: trl==0.4.7 in /home/surenoobster/.local/lib/python3.10/site-packages (0.4.7)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/surenoobster/.local/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/surenoobster/.local/lib/python3.10/site-packages (from transformers==4.34.0) (2.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.34.0) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/surenoobster/.local/lib/python3.10/site-packages (from transformers==4.34.0) (0.17.3)\n",
      "Requirement already satisfied: filelock in /home/surenoobster/.local/lib/python3.10/site-packages (from transformers==4.34.0) (3.16.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/surenoobster/.local/lib/python3.10/site-packages (from transformers==4.34.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/surenoobster/.local/lib/python3.10/site-packages (from transformers==4.34.0) (0.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from transformers==4.34.0) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/surenoobster/.local/lib/python3.10/site-packages (from transformers==4.34.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers==4.34.0) (2.25.1)\n",
      "Requirement already satisfied: multiprocess in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets==2.13.0) (0.70.14)\n",
      "Requirement already satisfied: pandas in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets==2.13.0) (2.2.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets==2.13.0) (2024.10.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets==2.13.0) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets==2.13.0) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets==2.13.0) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets==2.13.0) (3.11.10)\n",
      "Requirement already satisfied: psutil in /home/surenoobster/.local/lib/python3.10/site-packages (from peft==0.4.0) (6.1.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from peft==0.4.0) (2.5.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.13.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.13.0) (0.2.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.13.0) (1.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.13.0) (2.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.13.0) (24.2.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.13.0) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.13.0) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.13.0) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/surenoobster/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.3.1.170)\n",
      "Requirement already satisfied: jinja2 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (2.21.5)\n",
      "Requirement already satisfied: networkx in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/surenoobster/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.4.0) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets==2.13.0) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/surenoobster/.local/lib/python3.10/site-packages (from pandas->datasets==2.13.0) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/surenoobster/.local/lib/python3.10/site-packages (from pandas->datasets==2.13.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.13.0) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==2.13.0) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers==4.34.0\" \"datasets==2.13.0\" \"peft==0.4.0\" \"accelerate==0.23.0\" \"bitsandbytes==0.41.1\" \"trl==0.4.7\" \"safetensors>=0.3.1\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4884\n",
      "{'prompt': 'Write highlights for this article for a college student:\\n\\n', 'input_text': 'If Republicans should flip six or more Senate seats on Tuesday, they\\'ll control both houses of Congress for the first time in ten years, opening up a host of possibilities that the Democratic-run Senate has blocked under the currently Majority Leader, Nevada Sen. Harry Reid. Obamacare as we know it? No longer a guaranteed keeper. Immigration reform? Maybe, but on Republicans\\' terms. The Keystone XL pipeline? Built. Regulations that bring out the Ayn Rand in every conservative? Dead, at least for a time. Some legislation will still be off the table since President Barack Obama has a veto pen at the ready – and because Republicans themselves aren\\'t unified about how to respond to what Democrats have put in place in recent years. But the legislative game would be changed in some important and earth-shattering ways. Every Senate committee will have a Republican chairman or chairwoman in January if the GOP wins control on Tuesday. That will allow them to slow-walk legislation, or entirely refuse to entertain it, in the same way Reid has done since 2007. The powerful Judiciary Committee, especially, would become a game-changer, turning on its head the White House\\'s calculations when it chooses to appoint judges – including the next nominees to serve on the Supreme Court. In smaller ways, cogs in Obama\\'s governmental machine would find themselves, one at a time, without teeth. Scroll down for video . Mitch McConnell has been waiting ten years to become Senate Majority Leader; his testudinal grin says it all . Obama\\'s veto pen will get a workout if the GOP takes control on Tuesday, but he might be forced to face the difficult choice of whether to save unpopular laws or toss out crowd-pleasers . REPUBLICANS\\' LEAST FAVORITE REGULATIONS COULD STAND STILL . The Congressional Review Act of 1996 effectively gives Congress the power to block executive branch regulations at will – the kind issued daily by the EPA, the Food and Drug Administration, the Education Department, and countless other federal agencies and subagencies. All that\\'s required is for both houses of Congress to pass joint resolutions noting their disapproval. Just like that, the government rule in question is stopped in its tracks and robbed of any effect. Such resolutions require just a simple majority to pass in the Senate, meaning that with just 51 seats the GOP could team up with an expanding House majority to crush, or at least delay, a wide range of Obama administration initiatives during the president\\'s last term in office. Obama\\'s signature is still required on a resolution overturning a regulation, just like anything else that emerges from Congress. But while the White House wrangles over its PR strategy, the regulatory proposal would sit and collect dust. Republicans would then announce their intention to override the veto, an unlikely proposition since they lack two-thirds majorities in either house. But that process could be dragged out, and the Congressional Review Act would halt the regulation in question until 30 days after they officially give up. Everything from the administration\\'s EPA rules on coal-fired power plants and water pollution to minimum-wage hikes and unpopular moves that open the borders to Ebola patients could be open for debate, producing consistent howls from Democrats along the way. WE\\'LL FINALLY FIND OUT IF IT\\'S POSSIBLE TO REPEAL OBAMACARE . On a larger stage, changing or repealing the Obamacare law would be the ultimate prize for conservatives in the GOP. Democrats passed it during the president\\'s first term in office, when they controlled both houses of Congress. Not a single Republican voted in favor of the final bill. Obama at first resisted the GOP\\'s demands for changes to the law, but then put his own in place to delay its phased-in implementation until after the election. That has brought howls out of the right-wing\\'s woodwork, and the threat of a lawsuit from House Republicans since precise, hard-and-fast dates were written into the law. Obama, they say, lacked the power to change how the law was implemented without permission from Congress. Conservatives like Texas Sen. Ted Cruz favor sending a complete repeal bill to the White House now that Obamacare – and Obama himself – are wildly unpopular. That itself would be tough since it\\'s practically impossible that Republicans will hold 60 seats, the number required to force an end to a debate and call for a vote on legislation. But current Senate Majority Leader Mitch McConnell has signaled that he\\'s willing to use a special budget maneuver called \\'reconciliation\\' to get around that, setting the bar at just 51 votes. Reid invoked something similar in 2013 for the first time in America\\'s history – a play known as the \\'nuclear option\\' – to confirm a group of controversial judicial nominees without Republican support. Now it could be McConnell\\'s turn to move the levers. Should the president veto an Obamacare repeal bill or let it languish until it expires (a so-called \\'pocket veto\\'), right-wingers would then urge their leadership to pass a rapid-fire series of laws repealing Obamacare one piece at a time, forcing Obama to issue veto after veto and rebranding Democrats as \\'the party of \"No\".\\' Will he stick around? If longtime Majority Leader Harry Reid loses his top post, the Nevada Democrat might shirk the role of minority leader in favor of returning to the back bench . Voters in many states have been casting ballots for weeks, but D-Day officially comes Tuesday . CANADA\\'S KEYSTONE XL PIPELINE MIGHT BE COMPLETED . The White House will certainly hunker down in any event, portraying the Affordable Care Act as a blessing for the previously uninsured. Republicans will follow their lawsuit through the federal courts. Another game-changer could see an oil pipeline bringing unrefined petroleum from the expansive tar sands of Alberta, Canada to the Texas coastline on the Gulf of Mexico. The idea was described ten years ago as a job-creation miracle and a way to lower energy costs all across North America. But President Obama\\'s State Department, prodded by environmental groups, has slow-walked the project, crashing into hurdle after hurdle seemingly on purpose. Canada desperately wants the project to move forward. The alternative is to pipe as many as 830,000 barrels of oil westward every day toward the Pacific Ocean, where it would be refined and shipped to Asia. If the Keystone XL pipeline were built as planned, much of the finished fuel would go to China and India no matter what, but green groups have struck a \\'not in our backyard\\' pose and urged the White House to delay it as long as possible. But the State Department\\'s own review board ruled in January, after years of study, that the project would have a negligible impact on the environment. Whither Obamacare? With Senate and House conservatives both holding Democracy\\'s car keys, it\\'s not clear how much of the president\\'s hard-won medical insurance overhaul would survive by the end of his term . Armed with that document, a Republican-run Congress would likely pass a bill immediately funding the project and forcing Obama\\'s hand. The White House\\'s public position has long been that it\\'s not stalling – merely enduring a lengthy deliberative process to make sure it\\'s doing no harm. Republicans will force the issue if they win control of the Senate. And enough Democrats want the project built that Obama may have no choice but to go along. ILLEGAL IMMIGRANTS COULD GO FROM PROTECTED CLASS TO ENDANGERED SPECIES . They will also push back hard against what they see as Obama\\'s lawless moves to remake immigration policy in a way that gives unreasonable advantages to people who are in the U.S. illegally. At stake, they say, are the potential bankrupting of the American education system, the availability of jobs for U.S. citizens, the worsening of an already strained criminal justice system, and a host of other controversial shifts in what American life looks like. The White House has pined for a rewrite of U.S. immigration law since day one of Obama\\'s first term, but used all its political capital to get Obamacare passed – and never thought it would lose control of the House of Representatives in 2010. As a result, the Obama administration had to rely on a bipartisan \\'Gang of Eight\\' senators last year to craft an immigration proposal that might, just maybe, be palatable to House Republicans. The Senate bill passed, containing something for everyone: dramatically fewer deportations of illegal immigrants, increased border security and other political dog-whistles. But conservatives feared the White House couldn\\'t be trusted to hold up its end of the bargain, and the proposal never got a vote in the House. More walls: Any immigration proposal a new GOP-led Congress might approve would be guaranteed to focus on border security instead of on mainstreaming illegal immigrants – as the Obama administration has sought . Obama responded by unilaterally putting part of the bill into place with an executive order, guaranteeing that tens of thousands of people brought illegally to the U.S. as children could stay – at least as long as he holds the White House. He has pledged to go further still after Tuesday\\'s election. ANOTHER GOVERNMENT SHUTDOWN? IT\\'S POSSIBLE . Republicans want to be in a position to stop him, but even in their rosiest scenario they won\\'t take control until the new Congress takes office January 3. At that point they could use the power of the purse to deny Obama the money he needs to put his ideas into practice. But they have few weapons in the meantime, during the end-of-year \\'lame duck\\' session that\\'s likely to last a few weeks. One possibility is another threat of a government shutdown, since the last budget resolution Congress passed expires on December 11. House GOP leaders could hold that over the president\\'s head and threaten a budget standstill before Christmas in order to force his hand. A new war of words would surely follow, with Republicans calling the White House lawless and Democrats comparing the GOP to ill-mannered Grinches, jeopardizing the postal service and Americans\\' benefit checks during the busy holiday season. We\\'ve seen this movie before. It usually ends with the GOP backing down since it has controlled only the House of Representatives and can\\'t take action without House Democrats. This time could be different.', 'summary': \"Armed with majorities in both houses, a Republican-led Congress could embarrass President Obama into accepting changes to his health care law .\\nThe GOP could use a 1996 law to stop practically any regulation, at least until Obama vetoes a resolution and Republicans give up on an override – and then for 30 days more .\\nPresident's hoped-for immigration reform law would be dead in the water and Republicans could use their budget axe to gut his executive orders .\\nAn immediate funding mechanism to build the Keystone XL oil pipeline could be on the table by mid-January .\\nEvery Senate committee would be chaired by a Republican, changing the White House's calculation on everything from foreign policy to Supreme Court appointments .\"}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "\n",
    "# Path to the local JSON file\n",
    "file_path = \"/home/surenoobster/Documents/controllable-readability-summarization/Instruction_fin_tune_new/train_instruct_fine_tune_category.json\"\n",
    "\n",
    "# Load dataset from the local file\n",
    "dataset = load_dataset(\"json\", data_files=file_path, split=\"train\")\n",
    "\n",
    "# Print dataset details\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(dataset[randrange(len(dataset))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/surenoobster/.local/lib/python3.10/site-packages (2.13.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: packaging in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (3.11.10)\n",
      "Collecting huggingface-hub>=0.23.0\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 KB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Collecting fsspec[http]<=2024.9.0,>=2023.1.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 KB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/surenoobster/.local/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/surenoobster/.local/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/surenoobster/.local/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 KB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/surenoobster/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/surenoobster/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: fsspec, charset-normalizer, requests, huggingface-hub, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.13.0\n",
      "    Uninstalling datasets-2.13.0:\n",
      "      Successfully uninstalled datasets-2.13.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.27.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed charset-normalizer-3.4.0 datasets-3.2.0 fsspec-2024.9.0 huggingface-hub-0.27.0 requests-2.32.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fsspec==2023.9.2\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "Successfully installed fsspec-2023.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fsspec==2023.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/surenoobster/.cache/huggingface/datasets/json/default-a58aac04772f2e49/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa5b35e5a004644a40f6297851a2029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4c301d51014f51800211264356537d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea1a32cf6c54e50865bb1a17108cb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/surenoobster/.cache/huggingface/datasets/json/default-a58aac04772f2e49/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974f10944e994b09910927229306b548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 4884\n",
      "You are a personal stylist recommending fashion advice and clothing combinations. Use the self body and style description below, combined with the event described in the context to generate 5 self-contained and complete outfit combinations.\n",
      "        ### Input:\n",
      "        Yet another woman has stepped forward to accuse Bill Cosby of drugging her when she a young aspiring model. The woman, who identified herself only as Lisa, told Dr Phil in an exclusive interview that she was just 21 in 1988 when the comedian told her modeling agency that he wanted to meet her. 'I was very excited to go and see him,' Lisa told Dr. Phil, in an interview that will air in full on Friday. 'I was starstruck. I felt invincible. I couldn't believe that he wanted to see me.' When she met with him for the first time, 'he was a gentlemen and he was respectful and kind,' she said. 'He seemed very interested in me, and that made me feel very secure in seeing him again.' Scroll down for videos . Speaking out: Lisa, pictured, said she was just 21 when she was drugged by Bill Cosby in his hotel room . On another occasion, she took her sister and mother to meet him, and they were thrilled. 'My mother trusted Bill completely,' she said. 'I trusted him like I trusted my own father.' Then one day, he called her out of the blue and said he wanted to see her at his hotel room to give her career advice, she said. She went to his suite alone. While there, he said he wanted to see her acting skills and gave her some lines to read, she said. She claimed that he offered her a small, brown drink, saying it would relax her before reading the lines. She initially refused, saying she didn't drink, but he insisted so she acquiesced. 'He made a second drink and had me drink the second drink as well,' she said. 'I noticed myself getting a little dizzy.' Cosby sat on the edge of a couch and told her to sit down. He had his legs open and she sat between them with her back to his crotch, she said. 'He started to stroke my hair back in a petting motion,' she said. 'The last thing I remember is just feeling the strokes on my head. After that, I don't remember anything else.' Younger years: At the time, she was an aspiring model and Cosby had offered to give her career advice . 'We trusted him': Lisa said that Cosby even agreed to meet with her sister, center, and mother . Impressed: She said that her mother, pictured, trusted Cosby - but that that trust was ultimately broken . She said that she blacked out and woke up two days later in her own bed. During her interview, Dr Phil asked if she knew if the comedian had sexually assaulted her. 'No,' she responded. She said part of the problem in going to the police was that she did not know what had happened to her. But she wanted him to know that she knew he had done something wrong. Lisa joins more than two dozen women who have claimed in recent weeks that Cosby drugged and sexually assaulted them in incidents stretching back to the 1960s and as recently as the 2000s. Dr Phil told her that Cosby's daughter, Evin, had released a statement. 'Rape is a serious allegation, and it is supposed to be taken very seriously, but so is falsely accusing someone,' it read. 'When someone rapes a person they go to prison. That should also happen the person that has wrongfully accused an innocent victim.' Lisa responded: 'No one remembers after they were drugged. Little bits and pieces of what has happened when they were drugged, they remember everything up until they were drugged, but they don’t remember after. Anger: Lisa, left, spoke to Dr Phil with other women who say they were drugged and raped by Bill Cosby, including Helen Hayes (right), who said to Cosby and his wife: 'Shame on you, shame on you!' 'So where's that time? All of us just blacked out miraculously, because we were around Bill Cosby from the shock of him being a star? I mean honestly.' Although she had initially not wanted to speak out, she said she decided to come forward after model Janice Dickinson accused Cosby of raping her. On the show, Lisa was joined by six other accusers who have already spoken out against the comedian: Kristina Ruehli, PJ Masten, Victoria Valentino, Helen Hayes, Beth Ferrier and Chelan. 'A body knows when it’s raped,' Masten said on the show. 'You not only rape physically but you are raped emotionally. and your spirit is gone forever. And he is a serial rapist. We all have that same thing in common. We all feel that.' Hayes added: 'Hopefully it'll dissipate and I don't have to carry the shame anymore.' She also had a message for Bill and his wife, Camille Cosby, who has stood by her husband and slammed the media coverage of 'rumors' about her husband. 'Shame on you shame, shame on you, shame on you,' Hayes said. Standing by her man: Camille Cosby, pictured with her husband in November, broke her silence this week to slam the media's coverage of the accusations, suggesting it was Cosby who was the real victim . The show will air on Friday, and they will be joined by attorney Gloria Allred and Kathleen Phelps, a former Playboy bunny who maintains he is a respectful man and friend. Cosby  has denied any wrongdoing and no criminal charges have ever been brought - but in 2006, he did settle a civil lawsuit with a woman who claimed he drugged and raped her in 2004. Earlier this week, Camille Cosby broke her silence. She compared the media's handling of the reports to Rolling Stone's botched coverage of the UVA rape scandal. 'There appears to be no vetting of my husband's accusers before stories are published or aired,' she said. 'An accusation is published, and immediately goes viral... None of us will ever want to be in the position of attacking a victim. But the question should be asked - who is the victim?'\n",
      "\n",
      "        ### Context:\n",
      "        Write highlights for this article for a middle school student:\n",
      "\n",
      "\n",
      "\n",
      "        ### Response:\n",
      "        A woman named Lisa told Dr Phil that she was just 21 when Cosby asked to meet with her and gained the trust of her family .\n",
      "She says he invited her to his hotel room to run some lines and while there, he gave her a drink that made her feel dizzy .\n",
      "She said that the last thing she remembered was him rubbing her head as she sat between his legs; she woke up two days later in her bed .\n",
      "Lisa said she has no idea if she was sexually assaulted .\n",
      "She joins more than 20 women who have accused Cosby of drugging and assaulting them since the 1960s; he has denied the allegations .\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "\n",
    "# Path to your dataset\n",
    "train_data_path = \"/home/surenoobster/Documents/controllable-readability-summarization/Instruction_fin_tune_new/train_instruct_fine_tune_category.json\"\n",
    "\n",
    "# Load dataset from the local file\n",
    "custom_dataset = load_dataset(\"json\", data_files={\"train\": train_data_path})\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Train dataset size: {len(custom_dataset['train'])}\")\n",
    "\n",
    "# Preview a random sample\n",
    "sample = custom_dataset['train'][randrange(len(custom_dataset['train']))]\n",
    "\n",
    "# Format the instruction\n",
    "def format_instruction(sample):\n",
    "    return f\"\"\"You are a personal stylist recommending fashion advice and clothing combinations. Use the self body and style description below, combined with the event described in the context to generate 5 self-contained and complete outfit combinations.\n",
    "        ### Input:\n",
    "        {sample[\"input_text\"]}\n",
    "\n",
    "        ### Context:\n",
    "        {sample[\"prompt\"]}\n",
    "\n",
    "        ### Response:\n",
    "        {sample[\"summary\"]}\n",
    "    \"\"\"\n",
    "\n",
    "formatted_instruction = format_instruction(sample)\n",
    "\n",
    "# Print formatted instruction\n",
    "print(formatted_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/surenoobster/.cache/huggingface/datasets/json/default-a58aac04772f2e49/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0acba63922b446c8c06c77a7fcdab2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating max input and target lengths...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04225b89829344ad9776bb741c657792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9311a53c7f6e455fbf152db94f349a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max target length: 512\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a525e727024ac1aed01245994ab4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Model ID for FLAN-T5\n",
    "model_id = \"google/flan-t5-small\"\n",
    "\n",
    "# Load tokenizer for FLAN-T5\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Path to the formatted dataset\n",
    "train_path = \"/home/surenoobster/Documents/controllable-readability-summarization/Instruction_fin_tune_new/train_instruct_fine_tune_category.json\"\n",
    "\n",
    "# Load the formatted dataset\n",
    "data_files = {\"train\": train_path}\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# Compute maximum input and output lengths for efficient batching\n",
    "print(\"Calculating max input and target lengths...\")\n",
    "\n",
    "# Tokenize the concatenated dataset for inputs\n",
    "tokenized_inputs = dataset[\"train\"].map(\n",
    "    lambda x: tokenizer(x[\"input_text\"], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=[\"input_text\", \"summary\", \"prompt\"]\n",
    ")\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# Tokenize the concatenated dataset for targets\n",
    "tokenized_targets = dataset[\"train\"].map(\n",
    "    lambda x: tokenizer(x[\"summary\"], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=[\"input_text\", \"summary\", \"prompt\"]\n",
    ")\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    # Prepare inputs with a task prefix (e.g., \"summarize:\")\n",
    "    inputs = [\"summarize: \" + item for item in sample[\"input_text\"]]\n",
    "\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Replace padding token ID with -100 to ignore during loss computation\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"input_text\", \"summary\", \"prompt\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/surenoobster/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/surenoobster/.cache/huggingface/datasets/json/default-a58aac04772f2e49/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ec3f28ac51494a8792bffa0c64ace2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating max input and target lengths...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00771aa3608f4f099f8c15cfb9559db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae0e5d2bd9d4f7692e337b602e71409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max target length: 512\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ea7904232949808678db8a8fdcc0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['summary', 'prompt', 'input_text', 'input_ids', 'attention_mask', 'labels']\n",
      "Model, tokenizer, metric, and data collator loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load FLAN-T5 model\n",
    "model_id = \"google/flan-t5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Load ROUGE metric\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# Path to the formatted dataset\n",
    "train_path = \"/home/surenoobster/Documents/controllable-readability-summarization/Instruction_fin_tune_new/train_instruct_fine_tune_category.json\"\n",
    "\n",
    "# Load the formatted dataset\n",
    "data_files = {\"train\": train_path}\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# Compute maximum input and output lengths for efficient batching\n",
    "print(\"Calculating max input and target lengths...\")\n",
    "\n",
    "# Tokenize the concatenated dataset for inputs\n",
    "tokenized_inputs = dataset[\"train\"].map(\n",
    "    lambda x: tokenizer(x[\"input_text\"], truncation=True),\n",
    "    batched=True\n",
    ")\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# Tokenize the concatenated dataset for targets\n",
    "tokenized_targets = dataset[\"train\"].map(\n",
    "    lambda x: tokenizer(x[\"summary\"], truncation=True),\n",
    "    batched=True\n",
    ")\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    # Concatenate the prompt with the input_text (if prompt is present)\n",
    "    if \"prompt\" in sample:\n",
    "        inputs = [\"summarize: \" + item for item in sample[\"input_text\"]]\n",
    "        inputs = [f\"{item} {sample['prompt']}\" for item in inputs]  # Concatenate prompt with input_text\n",
    "    else:\n",
    "        inputs = [\"summarize: \" + item for item in sample[\"input_text\"]]\n",
    "\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Replace padding token ID with -100 to ignore during loss computation\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
    "\n",
    "# Helper function to postprocess text for evaluation\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # ROUGE expects newlines after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "# Compute metrics function for evaluation\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Post-process predictions and labels\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result\n",
    "\n",
    "# Define a DataCollator for Seq2Seq tasks\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=\"max_length\", label_pad_token_id=-100)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Model, tokenizer, metric, and data collator loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd5d479c8af4b0e8ee648cbcb73c47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.726229508196722e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0, 'learning_rate': 4.316393442622951e-05, 'epoch': 1.64}\n",
      "{'loss': 0.0, 'learning_rate': 3.9065573770491805e-05, 'epoch': 2.46}\n",
      "{'loss': 0.0, 'learning_rate': 3.49672131147541e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0, 'learning_rate': 3.08688524590164e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0, 'learning_rate': 2.677049180327869e-05, 'epoch': 4.91}\n",
      "{'loss': 0.0, 'learning_rate': 2.2672131147540984e-05, 'epoch': 5.73}\n",
      "{'loss': 0.0, 'learning_rate': 1.857377049180328e-05, 'epoch': 6.55}\n",
      "{'loss': 0.0, 'learning_rate': 1.4475409836065573e-05, 'epoch': 7.37}\n",
      "{'loss': 0.0, 'learning_rate': 1.037704918032787e-05, 'epoch': 8.19}\n",
      "{'loss': 0.0, 'learning_rate': 6.2786885245901634e-06, 'epoch': 9.01}\n",
      "{'loss': 0.0, 'learning_rate': 2.180327868852459e-06, 'epoch': 9.83}\n",
      "{'train_runtime': 3082.4973, 'train_samples_per_second': 15.844, 'train_steps_per_second': 1.979, 'train_loss': 0.0, 'epoch': 9.99}\n",
      "Training complete and model saved.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import torch\n",
    "\n",
    "# Define the data collator for Seq2Seq tasks\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./flan_t5_base_output\",  # Output directory for saving the model\n",
    "    overwrite_output_dir=True,  # Overwrite the output directory if it exists\n",
    "    per_device_train_batch_size=4,  # Batch size for each device (GPU/CPU)\n",
    "    gradient_accumulation_steps=2,  # Number of gradient accumulation steps\n",
    "    fp16=True,  # Use mixed-precision training if possible\n",
    "    learning_rate=5e-5,  # Learning rate\n",
    "    num_train_epochs=10,  # Number of epochs\n",
    "    logging_dir=\"./logs\",  # Directory for logs\n",
    "    logging_strategy=\"steps\",  # Log every 'steps' steps\n",
    "    logging_steps=500,  # Log every 500 steps\n",
    "    save_strategy=\"epoch\",  # Save the model every epoch\n",
    "    save_total_limit=2,  # Limit the number of saved models\n",
    "    evaluation_strategy=\"no\",  # No evaluation during training\n",
    "    report_to=[\"tensorboard\"],  # Use TensorBoard for reporting\n",
    ")\n",
    "\n",
    "# Initialize the Seq2Seq trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,  # The model to train\n",
    "    args=training_args,  # The training arguments\n",
    "    data_collator=data_collator,  # Data collator for padding and batching\n",
    "    train_dataset=tokenized_dataset[\"train\"],  # Tokenized training dataset\n",
    ")\n",
    "\n",
    "# Free memory before starting the training\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model(\"./final_model_CATEGORY_instruct_try\")\n",
    "\n",
    "# Save the tokenizer as well\n",
    "tokenizer.save_pretrained(\"./final_model_instruct_try\")\n",
    "\n",
    "print(\"Training complete and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readability_summ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
