{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/surenoobster/.cache/huggingface/datasets/json/default-9a3e761403c86782/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02ba486dbdb438aac58350985b16a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd30642ba84f4064986e2e5b37cd1160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba300d4a0944a788770d1acb5bf2cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/surenoobster/.cache/huggingface/datasets/json/default-9a3e761403c86782/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21f7661b59b4d86926db05c03569ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c5a52ec8f94d44a01805fc9b103b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted dataset saved to: /home/surenoobster/Documents/controllable-readability-summarization/src/18dec_retried_finalboss/read_for_scoreFREfinetune_flanT5.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Load your dataset from a local JSON file (adjust paths as needed)\n",
    "data_files = {\n",
    "    \"train\": \"/home/surenoobster/Documents/controllable-readability-summarization/src/18dec_retried_finalboss/train_score_category.json\",\n",
    "}\n",
    "\n",
    "# Load dataset from local files\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# Function to format dataset for fine-tuning (using `input` as input text and `summary` as the output)\n",
    "def format_for_finetuning(dataset):\n",
    "    formatted_data = []\n",
    "    for entry in dataset[\"train\"]:  # Access the 'train' split\n",
    "        # Use 'input' as the input text\n",
    "        input_text = entry[\"input\"]\n",
    "        output_text = entry[\"summary\"]  # Use 'summary' as the target output\n",
    "        \n",
    "        # Add formatted entry to the list\n",
    "        formatted_data.append({\n",
    "            \"input\": input_text,\n",
    "            \"output\": output_text\n",
    "        })\n",
    "    return formatted_data\n",
    "\n",
    "# Format the dataset\n",
    "formatted_dataset = format_for_finetuning(dataset)\n",
    "\n",
    "# Convert the formatted data into a Hugging Face Dataset for further processing\n",
    "formatted_dataset = Dataset.from_list(formatted_dataset)\n",
    "\n",
    "# Save the formatted dataset to a JSON file (optional)\n",
    "output_file = \"/home/surenoobster/Documents/controllable-readability-summarization/src/18dec_retried_finalboss/read_for_scoreFREfinetune_flanT5.json\"\n",
    "formatted_dataset.to_json(output_file)\n",
    "\n",
    "print(f\"Formatted dataset saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/surenoobster/.cache/huggingface/datasets/json/default-2fa289790e7b13c7/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48667001f384f22af10ccef3b1b6958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dad9e99efda453f85ea035fd029d245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac95f07a6c5410ba44de3e0c260dc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/surenoobster/.cache/huggingface/datasets/json/default-2fa289790e7b13c7/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbca2ba546246ce9fa783c138afa235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 4884\n",
      "Input (Prompt + Article): \n",
      "Write highlights for this article with a Flesch-Kincaid score of 45:\n",
      "\n",
      "By . Daily Mail Reporter . and Ap . The woman featured in a photograph that shocked the world last year - that shows her giving birth on the lawn of a medical clinic after she was refused treatment by health officials - has made a full recovery and is in perfect health, as is her five-month-old son, Sabino. Additionally, the attention her shocking photo received has inspired women's rights activists across the globe to end what they call a pattern of poor . indigenous Mexican women being turned away from hospitals while in . labor, forcing them to give birth on lawns, patios or parking lots. The shocking image, taken in October by a passerby, . shows 29-year-old Irma Lopez , who is of Mazatec ethnicity, squatting . after giving birth, her face contorted in pain and her tiny newborn son . still bound by the umbilical cord and lying on the ground. Healthy: Irma Lopez and her son Sabino went through labor on the lawn of a medical clinic that turned her away . At the time the photo was taken, Lopez was sitting on a patch of grass outside a medical center that had refused to treat her. On Thursday, women's rights advocates sought international help to fix the troublesome pattern of women being turned away from medical clinics. Activists working in villages in southern Mexico say they have documented at least 20 recent cases of women giving birth outside hospitals whose staff claimed there was no room. Photos and video of some incidents posted on social media sites have prompted outrage in Mexico and around the world. Mexican health officials have said the cases are isolated and unavoidable due to overcrowding and limited resources at some rural health centers. But women's advocates appealed to the Inter-American Commission on Human Rights on Thursday, saying they believe there is a systemic problem of prejudice and callousness toward indigenous women in the Mexican public health system. Scandalous: This disturbing photo of Irma Lopez, 29, squatting in pain outside a Mexican health clinic after giving birth without help from the staff caused outrage after appearing on the front page of La Razon de Mexico . 'These are not isolated cases. We . have a pattern. We are not talking about one woman. There are many and . nothing is being done to solve the problem,' said Regina Tames, director . of the Reproductive Choice Information Group, a non-governmental . organization based in Mexico City. Pablo . Kuri Morales, deputy health secretary for preventive care, said most of . the births in Mexico's health system occur without problems but he . acknowledged that hundreds of women here still die every year during or . immediately after they give birth, giving the country a maternal death . rate more than three times that in the U.S. This . is something the government of Mexico is worried about. Our stand now . is to reject, disapprove and fight with all our strength any form of . violence against women,' Kuri Morales said. Many of these problems were ignored until the photo of Lopez was shared across the world - as well as across Mexico. Happy mother: Irma Lopez stands next to her newborn son Salvador at a clinic in the town of Jalapa de Diaz, Mexico, where a health center director was suspended for failing to help her during birth . The . picture upset many Mexicans when it was widely shared on Twitter and . Facebook and shown on the front pages of some national dailies. News . about the outdoor birth prompted two other women to go public with . their own harrowing tales of having their babies born outside the same . center. Less than a week later, authorities fired the director of . another hospital after a video showing a woman giving birth in a waiting . room was posted on YouTube. Television news channels in Oaxaca state . showed a woman having a baby in the dark courtyard outside the General . Hospital of Huajuapan de Leon. In another case, an 18-year-old . indigenous woman gave birth in the bathroom of a shelter next to a . hospital after allegedly being refused medical care. 'This . probably has been going on for a while,' said Tames. 'What's new is . that people are outraged and want to do something about it.' Earlier . this month, President Enrique Pena Nieto urged hospitals not to refuse . care to women in labor. Also, Oaxaca Gov. Gabino Cue recently announced a . $550,000 investment to set up 50 new delivery rooms across the state. But . just this week, local media reported the case of a woman feeling . contractions who had been sent away by a hospital and was only . re-admitted after photographers began arriving. None . of the women or babies have died or suffered from major health . problems, but Tames said authorities shouldn't wait for a death before . adding more resources to understaffed rural clinics and hospitals. Most . of the cases that have gone public have occurred in Oaxaca. The largely . rural southern state is among Mexico's poorest and suffers from high . rates of obstetrical problems including preeclampsia, a condition that . causes high blood pressure in women during pregnancy that can lead to . kidney or liver failure. A . handful of similar cases have been reported in Puebla and Chiapas, also . states with large indigenous populations and high rates of obstetrical . problems and maternal deaths. The . human rights commission will study the cases heard Thursday and can . send resolutions that are non-binding based on what it finds. Although . authorities fired the director of the first health center to draw . attention to the problem, the Oaxaca state medical regulatory committee . weeks later ruled that Irma Lopez's case was not the result of . negligence and called the birth an unforeseeable event. Lopez hopes the attention her case has brought to the state will help lead to better care for indigenous pregnant women. 'I hope that we find the support in the end. We are peasants and housewives.' Growing brood: The 29-year-old mother of three talks to her children as her newborn son Salvador sleeps on her lap at her hut in the town of Jalapa de Diaz, Mexico . Earlier . this month, President Enrique Pena Nieto urged hospitals not to refuse . care to women in labor. Also, Oaxaca Gov. Gabino Cue recently announced a . $550,000 investment to set up 50 new delivery rooms across the state. But . just this week, local media reported the case of a woman feeling . contractions who had been sent away by a hospital and was only . re-admitted after photographers began arriving. None . of the women or babies have died or suffered from major health . problems, but Tames said authorities shouldn't wait for a death before . adding more resources to understaffed rural clinics and hospitals. Most . of the cases that have gone public have occurred in Oaxaca. The largely . rural southern state is among Mexico's poorest and suffers from high . rates of obstetrical problems including preeclampsia, a condition that . causes high blood pressure in women during pregnancy that can lead to . kidney or liver failure. A . handful of similar cases have been reported in Puebla and Chiapas, also . states with large indigenous populations and high rates of obstetrical . problems and maternal deaths. The . human rights commission will study the cases heard Thursday and can . send resolutions that are non-binding based on what it finds. Although . authorities fired the director of the first health center to draw . attention to the problem, the Oaxaca state medical regulatory committee . weeks later ruled that Irma Lopez's case was not the result of . negligence and called the birth an unforeseeable event. Lopez hopes the attention her case has brought to the state will help lead to better care for indigenous pregnant women. 'I hope that we find the support in the end. We are peasants and housewives.'\n",
      "---------------\n",
      "Output (Summary): \n",
      "Pregnant Irma Lopez, 29, and her husband - both ethnic Mazatec - walked October 2 to clinic in Oaxaca, but were turned away by nurses .\n",
      "Photo of grimacing Lopez kneeling on patch of grass outside clinic with her newborn son still attached by umbilical cord set off firestorm online .\n",
      "Clinic director Dr Adrian Cruz was suspended pending state and federal investigations .\n",
      "Nurses at health clinic blamed 'misunderstanding' on language barrier and being short-staffed .\n",
      "Lopez and her baby, Sabino, made full recoveries .\n",
      "Her story has inspired women's health advocates to push for reforms that will prevent this sort of thing from happening again .\n",
      "Advocates say it is common for pregnant women to be turned away from medical clinics in Mexico .\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Path to your dataset\n",
    "train_data_path = \"/home/surenoobster/Documents/controllable-readability-summarization/src/18dec_retried_finalboss/read_for_scoreFREfinetune_flanT5.json\"\n",
    "\n",
    "# Load dataset from the local file\n",
    "custom_dataset = load_dataset(\"json\", data_files={\"train\": train_data_path})\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Train dataset size: {len(custom_dataset['train'])}\")\n",
    "\n",
    "# Preview a random sample\n",
    "from random import randrange\n",
    "\n",
    "sample = custom_dataset['train'][randrange(len(custom_dataset['train']))]\n",
    "print(f\"Input (Prompt + Article): \\n{sample['input']}\\n---------------\")\n",
    "print(f\"Output (Summary): \\n{sample['output']}\\n---------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/surenoobster/.cache/huggingface/datasets/json/default-2fa289790e7b13c7/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedb37db2ef64a6187bcd870c0540fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating max input and target lengths...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398e30d939d148a6a98e057524898851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b5037fe7394689b110727e8ece8b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max target length: 512\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9877bb3c1e43a0848f5f0d2605a0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "# Model ID for FLAN-T5\n",
    "model_id = \"google/flan-t5-small\"\n",
    "\n",
    "# Load tokenizer for FLAN-T5\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Path to the formatted dataset\n",
    "train_path = \"/home/surenoobster/Documents/controllable-readability-summarization/src/18dec_retried_finalboss/read_for_scoreFREfinetune_flanT5.json\"\n",
    "\n",
    "# Load the formatted dataset\n",
    "data_files = {\"train\": train_path}\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# Compute maximum input and output lengths for efficient batching\n",
    "print(\"Calculating max input and target lengths...\")\n",
    "\n",
    "# Tokenize the concatenated dataset for inputs\n",
    "tokenized_inputs = dataset[\"train\"].map(\n",
    "    lambda x: tokenizer(x[\"input\"], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=[\"input\", \"output\"]\n",
    ")\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# Tokenize the concatenated dataset for targets\n",
    "tokenized_targets = dataset[\"train\"].map(\n",
    "    lambda x: tokenizer(x[\"output\"], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=[\"input\", \"output\"]\n",
    ")\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    # Prepare inputs with a task prefix (e.g., \"summarize:\")\n",
    "    inputs = [\"summarize: \" + item for item in sample[\"input\"]]\n",
    "\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"output\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Replace padding token ID with -100 to ignore during loss computation\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readability_summ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
